{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project 2 - Part 2 - Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charles\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaned Machine Learning ready data from part 1\n",
    "MS_Data = {}\n",
    "MS_Data = pd.read_csv(r'''C:\\Users\\Charles\\Desktop\\Data Science\\Capstone Project 2\\MS_Data.csv''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351775 14\n"
     ]
    }
   ],
   "source": [
    "r, c = MS_Data.shape\n",
    "print(r, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>Loan_Amount</th>\n",
       "      <th>Debt_To_Income_Ratio</th>\n",
       "      <th>Employment_Length</th>\n",
       "      <th>Normalized_Risk_Score</th>\n",
       "      <th>Approved_Reject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.005376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.848291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.723834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.831320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>2</td>\n",
       "      <td>0.384967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8  Loan_Amount  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0        500.0   \n",
       "1  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0        500.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0        500.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0        500.0   \n",
       "4  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0        500.0   \n",
       "\n",
       "   Debt_To_Income_Ratio  Employment_Length  Normalized_Risk_Score  \\\n",
       "0                0.3060                  6              -0.005376   \n",
       "1                0.0000                  1              -0.848291   \n",
       "2                0.0575                  2              -0.723834   \n",
       "3                0.0431                  1              -0.831320   \n",
       "4                0.0904                  2               0.384967   \n",
       "\n",
       "   Approved_Reject  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MS_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and test set.\n",
    "X = MS_Data.drop('Approved_Reject',axis=1).values\n",
    "y = (MS_Data['Approved_Reject']).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "Assumes anything over 40% debt to income ratio or Employment_Length < 1year to be rejected and anything else to be approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.       ,    0.       ,    0.       ,    0.       ,\n",
       "          0.       ,    0.       ,    0.       ,    1.       ,\n",
       "          0.       , 4000.       ,    0.1747   ,    0.       ,\n",
       "         -0.0665831])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out data in easy to read format\n",
    "np.set_printoptions(suppress=True)\n",
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement baseline formula\n",
    "baseline = []\n",
    "baseline = np.where(X_test[:,10] > 0.4, 0, np.where(X_test[:,11] == 0, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70355,)\n",
      "(70355, 13)\n"
     ]
    }
   ],
   "source": [
    "print(baseline.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.90      0.93     49228\n",
      "          1       0.80      0.91      0.85     21127\n",
      "\n",
      "avg / total       0.91      0.90      0.90     70355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9028924738824533\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(baseline, y_test))\n",
    "#very high accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The results are actually very strong using the baseline method. Lets see if Machine Learning methods can imporve on this \n",
    "#existing strong prediction ability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[19150  1977]\n",
      " [ 4855 44373]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, baseline,labels=[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "LR_predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.93      0.89     49228\n",
      "          1       0.80      0.62      0.70     21127\n",
      "\n",
      "avg / total       0.83      0.84      0.83     70355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,LR_predictions))\n",
    "#Recall = TP/(TP+FN)\n",
    "#Precision = TP/(TP+FP)\n",
    "#low score across the board. lower than baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8382630943074408\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(LR_predictions, y_test))\n",
    "#accuracy = (TP+FN)/Total Num of Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the performance is actually significantly worse than baseline where no machine learning was used. \n",
    "#the only thing LR performed better in is Negative Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9108803248709033"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, logmodel.predict_proba(X_test)[:, 1])\n",
    "#second method to get AUC score. without crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score by default does not shuffle when applying stratification sampling. Raw data is sorted by time series and labeling\n",
    "#so random shuffle is important to generate consistent result\n",
    "cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "LR_cv_score = cross_val_score(logmodel,X, y, cv=cv,scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All AUC Scores\n",
      "[0.91160825 0.91364171 0.91200162]\n",
      "\n",
      "\n",
      "AUC Score\n",
      "0.9124171935405014\n"
     ]
    }
   ],
   "source": [
    "print(\"All AUC Scores\")\n",
    "print(LR_cv_score)\n",
    "print('\\n')\n",
    "print(\"AUC Score\")\n",
    "print(LR_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the AUC score is actually very strong for Logistic Regression but we can do better with other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[13083  8044]\n",
      " [ 3335 45893]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, LR_predictions,labels=[1,0]))\n",
    "#left label: predicted class\n",
    "#top label: actual class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf.fit(X_train, y_train)\n",
    "RF_predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     49228\n",
      "          1       0.92      0.92      0.92     21127\n",
      "\n",
      "avg / total       0.95      0.95      0.95     70355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,RF_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952270627531803\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(RF_predictions, y_test))\n",
    "#much higher accuracy than baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9897547431341185"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC curve the is prefered choice over accuracy for binary classification\n",
    "\n",
    "cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "rfc_cv_score = cross_val_score(rf,X, y, cv=cv,scoring='roc_auc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All AUC Scores\n",
      "[0.98956646 0.98970648 0.98935538]\n",
      "\n",
      "\n",
      "AUC Score\n",
      "0.9895427738524619\n"
     ]
    }
   ],
   "source": [
    "print(\"All AUC Scores\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"AUC Score\")\n",
    "print(rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[19483  1644]\n",
      " [ 1714 47514]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, RF_predictions,labels=[1,0]))\n",
    "#left label: predicted class\n",
    "#top label: actual class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is noticably better in all four quandrants compared to logistic regression.\n",
    "#True positive and True Negative are both much higher while False Positive and False Negative are lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', 'Loan_Amount', 'Debt_To_Income_Ratio', 'Employment_Length', 'Normalized_Risk_Score']\n"
     ]
    }
   ],
   "source": [
    "#create list of features\n",
    "feature_list= list(MS_Data.drop('Approved_Reject',axis=1).columns)\n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00086 0.00077 0.00076 0.00037 0.0006  0.00059 0.00055 0.00118 0.0008\n",
      " 0.08303 0.12298 0.55828 0.22923]\n"
     ]
    }
   ],
   "source": [
    "#create importance metric for the features\n",
    "importances = list(rf.feature_importances_)\n",
    "round_importance = np.round(importances,5)\n",
    "print(round_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Employment_Length    Importance: 0.55828\n",
      "Variable: Normalized_Risk_Score Importance: 0.22923\n",
      "Variable: Debt_To_Income_Ratio Importance: 0.12298\n",
      "Variable: Loan_Amount          Importance: 0.08303\n",
      "Variable: 7                    Importance: 0.00118\n",
      "Variable: 0                    Importance: 0.00086\n",
      "Variable: 8                    Importance: 0.0008\n",
      "Variable: 1                    Importance: 0.00077\n",
      "Variable: 2                    Importance: 0.00076\n",
      "Variable: 4                    Importance: 0.0006\n",
      "Variable: 5                    Importance: 0.00059\n",
      "Variable: 6                    Importance: 0.00055\n",
      "Variable: 3                    Importance: 0.00037\n"
     ]
    }
   ],
   "source": [
    "feature_importances = [(feature, round_importance) for feature, round_importance in zip(feature_list, round_importance)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "#as expected employment length takes priority but the next 3 features are also quite important.\n",
    "#the regions are shown to be not important at all for prediction purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XG_model = XGBClassifier()\n",
    "XG_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charles\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "XG_predictions = XG_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     49228\n",
      "          1       0.93      0.92      0.92     21127\n",
      "\n",
      "avg / total       0.95      0.95      0.95     70355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,XG_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results are so close to Random Forest that at two decimal places, Precision, Recall, F1-Score, and Support are identical\n",
    "#between XGBoost and Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[19405  1722]\n",
      " [ 1449 47779]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, XG_predictions,labels=[1,0]))\n",
    "#left label: predicted class\n",
    "#top label: actual class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#True Positive is actually slightly lower for XGBoost relative to Random Forest but True Negative is better for ]\n",
    "#XGBoost which is why it has slightly higher AUC score seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All AUC Scores\n",
      "[0.98907817 0.99026786 0.98940638]\n",
      "\n",
      "\n",
      "AUC Score\n",
      "0.9895841352306004\n"
     ]
    }
   ],
   "source": [
    "cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "XG_cv_score = cross_val_score(XG_model,X, y, cv=cv,scoring='roc_auc')\n",
    "print(\"All AUC Scores\")\n",
    "print(XG_cv_score)\n",
    "print('\\n')\n",
    "print(\"AUC Score\")\n",
    "print(XG_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The AUC score for XGBoost is essentially the same as Random Forest but is significantly better than logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Employment_Length    Importance: 0.817799985408783\n",
      "Variable: Normalized_Risk_Score Importance: 0.094030000269413\n",
      "Variable: Debt_To_Income_Ratio Importance: 0.05299000069499016\n",
      "Variable: Loan_Amount          Importance: 0.035179998725652695\n",
      "Variable: 0                    Importance: 0.0\n",
      "Variable: 1                    Importance: 0.0\n",
      "Variable: 2                    Importance: 0.0\n",
      "Variable: 3                    Importance: 0.0\n",
      "Variable: 4                    Importance: 0.0\n",
      "Variable: 5                    Importance: 0.0\n",
      "Variable: 6                    Importance: 0.0\n",
      "Variable: 7                    Importance: 0.0\n",
      "Variable: 8                    Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "XG_importances = list(XG_model.feature_importances_)\n",
    "XG_round_importance = np.round(XG_importances,5)\n",
    "XG_feature_importances = [(feature, XG_round_importance) for feature, XG_round_importance in zip(feature_list, XG_round_importance)]\n",
    "XG_feature_importances = sorted(XG_feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in XG_feature_importances];\n",
    "\n",
    "#compared to random forest, the focus on Employment_Length is significantly higher. \n",
    "#All other features have been reduced in importance\n",
    "#The Regions are completely removed under XGBoost. In random forest there is still some importance in prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given how strong XGBoost and Random Forest performance scores are, there is no need to try out other types of model.\n",
    "#They are noticably better than the baseline method and suffice for the purpose of this project. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
